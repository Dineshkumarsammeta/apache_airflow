# Apache Airflow Projects  
This repository contains a set of workflows/DAGs built using **Apache Airflow** to support automation, scheduling, monitoring and orchestration of data pipelines.

## üìã Table of Contents  
- [About](#about)  
- [Features](#features)  
- [Repository Structure](#repository‚Äêstructure)  
- [Getting Started](#getting‚Äêstarted)  
  - [Prerequisites](#prerequisites)  
  - [Installation](#installation)  
  - [Running the Web Server & Scheduler](#running‚Äêthe‚Äêweb‚Äêserver‚Äêscheduler)  
- [Usage](#usage)  
  - [How to Add a DAG](#how‚Äêto‚Äêadd¬≠a‚Äêdag)  
  - [How to Trigger & Monitor](#how‚Äêto‚Äêtrigger‚Äêmonitor)  
- [Configuration](#configuration)  
- [Best Practices](#best‚Äêpractices)  
- [License](#license)  
- [Contributing](#contributing)  
- [Contact](#contact)  

## About  
This project is designed to manage, schedule and monitor data workflows using Apache Airflow. It includes a set of sample and production-ready DAGs (Directed Acyclic Graphs) that demonstrate good practices for orchestration, logging, dependency management, and error handling.

## Features  
- üöÄ Scalable task scheduling and orchestration using Airflow‚Äôs core concepts (DAGs, Operators, Tasks)  
- Modular DAGs stored in a `dags/` folder for clarity  
- Logs persisted in `logs/` folder for auditing and troubleshooting  
- Example configuration files (e.g., `airflow.cfg`, `webserver_config.py`) to customise behaviour  
- Extensible ‚Äî add your own DAGs, operators, hooks easily  

## Repository Structure  
‚îú‚îÄ‚îÄ dags/ # Airflow DAG definitions
‚îú‚îÄ‚îÄ logs/ # Airflow task logs
‚îú‚îÄ‚îÄ airflow.cfg # Airflow configuration file
‚îú‚îÄ‚îÄ webserver_config.py # Webserver custom configuration
‚îú‚îÄ‚îÄ airflow.db # SQLite DB for local dev (not recommended for production)
‚îî‚îÄ‚îÄ README.md # This file

bash
Copy code

## Getting Started  

### Prerequisites  
- Python 3.7+  
- pip  
- A virtual environment tool (recommended: `venv` or `conda`)  
- (For production) A more robust metadata database (PostgreSQL/MySQL) and message broker (RabbitMQ/Redis)  

### Installation  
```bash
# Clone the repository  
git clone https://github.com/Dineshkumarsammeta/apache_airflow.git  
cd apache_airflow  

# Create and activate virtual environment  
python3 -m venv .venv  
source .venv/bin/activate    # On Windows: .venv\Scripts\activate  

# Install dependencies  
pip install apache-airflow  # or pin a version: apache-airflow==2.x.x  
Running the Web Server & Scheduler
bash
Copy code
# Initialise the metadata database (for first time)  
airflow db init  

# Create a user for the web UI (one-time)  
airflow users create \
    --username admin \
    --firstname Admin \
    --lastname User \
    --role Admin \
    --email admin@example.com  

# Start the web server  
airflow webserver --port 8080  

# In another shell, start the scheduler  
airflow scheduler  
Then open your browser pointing to http://localhost:8080 to view the Airflow UI.

Usage
How to Add a DAG
Copy your DAG file to the dags/ directory.

Follow naming conventions (e.g., example_my_dag.py) and ensure dag_id, schedule, default_args are set.

The DAG will appear in the UI shortly after the scheduler detects it.

How to Trigger & Monitor
Use the UI to trigger DAG runs manually or rely on schedule_interval.

Monitor task status, logs and retries via the UI.

Logs for each task run are available under the logs/ folder.

Configuration
You can customise behaviour via airflow.cfg and webserver_config.py.
Some key settings you may want to adjust:

executor (e.g., LocalExecutor, CeleryExecutor)

sql_alchemy_conn to point to a production-grade database

dags_folder to change where DAGs are picked up

base_log_folder to change log storage

Best Practices
Version control your DAGs and dependencies.

Do not use SQLite for production metadata; switch to PostgreSQL or MySQL.

Use LocalExecutor only for small deployments; use CeleryExecutor / Kubernetes for scale.

Isolate tasks (idempotent, retryable).

Use connection IDs and variables instead of hard‚Äêcoding credentials.

Use branching, task groups, sub-DAGs for complex workflows.

Monitor and alert on failures, retries, SLA misses.

License
This project is released under the MIT License ‚Äî see LICENSE for details.

Contributing
Contributions are welcome! Whether it‚Äôs a bug fix, new feature or improved documentation:

Fork the repository

Create your feature branch (git checkout -b feature-xyz)

Commit your changes (git commit -m 'Add new DAG for xyz')

Push to the branch (git push origin feature-xyz)

Open a Pull Request and describe your changes

Contact
Maintainer: Dinesh Kumar Sammeta
GitHub profile: https://github.com/Dineshkumarsammeta
Feel free to open issues or pull requests for feedback or suggestions.
